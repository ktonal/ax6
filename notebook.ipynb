{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimikit as mmk\n",
    "import h5mapper as h5m\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from models.wavenets import WaveNetFFT\n",
    "from models.srnns import SampleRNN\n",
    "from models.s2s import Seq2SeqLSTM, Seq2SeqLSTMv0, Seq2SeqMuLaw\n",
    "from mains import train, generate\n",
    "\n",
    "from datasets import from_gcloud, LUNGS, Trainset\n",
    "from grids import *\n",
    "\n",
    "if os.path.exists(\"train.h5\"):\n",
    "    os.remove(\"train.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ded90",
   "metadata": {},
   "source": [
    "# Seq2Seq MuLaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acea1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for train_file in [*h5m.FileWalker(h5m.Sound.__re__, 'train-data/sounds')][2:]:\n",
    "\n",
    "#     h5m.sound_bank.callback(\"train.h5\", train_file, sr=22050,)\n",
    "\n",
    "#     soundbank = h5m.TypedFile(\"train.h5\", mode='r', keep_open=True)\n",
    "    \n",
    "net_grid = instance_grid(Seq2SeqMuLaw, \n",
    "                         dict(mlp_dim=512,\n",
    "                              input_dim=128,\n",
    "                              feature=mmk.MuLawSignal(q_levels=128, sr=16000)\n",
    "                             ),\n",
    "                         sampler_zipper(32,\n",
    "                                        ParameterGrid(dict(hop=[32,],\n",
    "                                                           with_sampler=[True, False],\n",
    "                                                           bias=[False],\n",
    "                                                           model_dim=[256],\n",
    "                                                           n_lstm=[1],\n",
    "                                                           with_tbptt=[True]))))\n",
    "    \n",
    "id_, s = [*COUGH.items()][0]\n",
    "\n",
    "for net in net_grid:\n",
    "    feature = net.feature\n",
    "    \n",
    "    class GCPSoundBank(h5m.TypedFile):\n",
    "        snd = from_gcloud(h5m.Sound(sr=feature.sr, mono=True, normalize=True))\n",
    "    \n",
    "    \n",
    "    GCPSoundBank.create(f\"train.h5\", s, parallelism=\"threads\", n_workers=8)\n",
    "    soundbank = GCPSoundBank(f\"train.h5\", mode='r', keep_open=True)\n",
    "    \n",
    "    print(net.hp)\n",
    "    \n",
    "    \n",
    "#     feature = mmk.Spectrogram(sr=soundbank.snd.attrs[\"sr\"],\n",
    "#                                 n_fft=1024, hop_length=256,\n",
    "#                                 coordinate='mag',\n",
    "#                                 center=False,\n",
    "#                                 normalize=True)\n",
    "\n",
    "#     net = Seq2SeqLSTM(\n",
    "#         feature=feature,\n",
    "#         input_heads=1,\n",
    "#         output_heads=1,\n",
    "#         scaled_activation=False,\n",
    "#         model_dim = 256,\n",
    "#         num_layers = 1,\n",
    "#         n_lstm = 1,\n",
    "#         bottleneck = \"add\",\n",
    "#         n_fc = 1,\n",
    "#         hop = 4,\n",
    "#         weight_norm=False,\n",
    "#         with_tbptt=False,\n",
    "#     )\n",
    "\n",
    "    optims = next(n_choices(optim_grid(), 1))\n",
    "    print(net.hp.__class__(**optims))\n",
    "    is_tbptt = (1+int(net.hp.with_tbptt)*1)\n",
    "    train(\n",
    "        soundbank,\n",
    "        net,\n",
    "        input_feature=feature,\n",
    "        target_feature=feature,\n",
    "        root_dir=\"./trainings/s2s-cough-qx\",\n",
    "        \n",
    "#         batch_size=8,\n",
    "        batch_length=net.hop * is_tbptt,\n",
    "        tbptt_chunk_length=(net.hop*is_tbptt) if net.hp.with_tbptt else None,\n",
    "        shift_error=0,\n",
    "        downsampling=1,\n",
    "        oversampling=1 if net.hp.with_tbptt else None,\n",
    "        \n",
    "        max_epochs=30,\n",
    "        limit_train_batches=4000,\n",
    "        **optims,\n",
    "#         max_lr=4e-4,\n",
    "#         betas=(0.9, 0.92),\n",
    "        div_factor=5,\n",
    "        final_div_factor=1.,\n",
    "        pct_start=0.,\n",
    "        cycle_momentum=False,\n",
    "\n",
    "        CHECKPOINT_TRAINING=False,\n",
    "        MONITOR_TRAINING=True,\n",
    "        OUTPUT_TRAINING=\"\",\n",
    "\n",
    "        every_n_epochs=5,\n",
    "        n_examples=4,\n",
    "        prompt_length=net.hop,\n",
    "        n_steps=int(6*(net.feature.sr) // net.hp.hop),\n",
    "        temperature=torch.tensor([[[1.1]], [[1.]], [[.5]], [[.25]]]).repeat(1, 1, int(6*(net.feature.sr))),\n",
    "        \n",
    "        trainset=id_\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf94a09",
   "metadata": {},
   "source": [
    "# Seq2Seq FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260607f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fft_grid():\n",
    "    return ParameterGrid(dict(feature=instance_grid(\n",
    "        mmk.Spectrogram, dict(center=False),\n",
    "        ParameterGrid([\n",
    "            dict(sr=[44100],\n",
    "                 )]),\n",
    "        [\n",
    "#             dict(n_fft=2048, hop_length=256),\n",
    "            dict(n_fft=1024, hop_length=256),\n",
    "        ],\n",
    "        ParameterGrid([\n",
    "            dict(coordinate=[\"mag\"])\n",
    "        ]),\n",
    "    )))\n",
    "\n",
    "def optim_grid():\n",
    "    return instance_grid(\n",
    "        None,\n",
    "        dict(),\n",
    "        ParameterGrid([\n",
    "            dict(\n",
    "                batch_size=[8, 16, 32],\n",
    "                max_lr=[6e-4, 5e-4, 4e-4],\n",
    "                betas=[(0.9, 0.915), (0.92, 0.92), (0.91846, 0.925), (0.95, 0.95), (0.925, 0.97)],\n",
    "            )\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "net_grid = instance_grid(Seq2SeqLSTM, \n",
    "                         dict(),\n",
    "                         sampler_zipper(8,\n",
    "                                        fft_grid(),\n",
    "                                        ParameterGrid(dict(hop=[4, 8],\n",
    "                                                           input_heads=[1],\n",
    "                                                           output_heads=[1],\n",
    "                                                           scaled_activation=[True, False],\n",
    "                                                           bias=[False],\n",
    "                                                           model_dim=[512],\n",
    "                                                           n_lstm=[1],\n",
    "                                                           with_tbptt=[False],\n",
    "                                                           with_sampler=[True, False]\n",
    "                                                          )))\n",
    "                         )\n",
    "    \n",
    "id_, s = [*LUNGS.items()][0]\n",
    "\n",
    "for net in net_grid:\n",
    "    feature = net.feature\n",
    "    \n",
    "    class GCPSoundBank(h5m.TypedFile):\n",
    "        snd = from_gcloud(h5m.Sound(sr=feature.sr, mono=True, normalize=True))\n",
    "    \n",
    "    \n",
    "    GCPSoundBank.create(f\"train.h5\", s, parallelism=\"threads\", n_workers=8)\n",
    "    soundbank = GCPSoundBank(f\"train.h5\", mode='r', keep_open=True)\n",
    "    \n",
    "    print(net.hp)\n",
    "    \n",
    "    \n",
    "#     feature = mmk.Spectrogram(sr=soundbank.snd.attrs[\"sr\"],\n",
    "#                                 n_fft=1024, hop_length=256,\n",
    "#                                 coordinate='mag',\n",
    "#                                 center=False,\n",
    "#                                 normalize=True)\n",
    "\n",
    "#     net = Seq2SeqLSTM(\n",
    "#         feature=feature,\n",
    "#         input_heads=1,\n",
    "#         output_heads=1,\n",
    "#         scaled_activation=False,\n",
    "#         model_dim = 256,\n",
    "#         num_layers = 1,\n",
    "#         n_lstm = 1,\n",
    "#         bottleneck = \"add\",\n",
    "#         n_fc = 1,\n",
    "#         hop = 4,\n",
    "#         weight_norm=False,\n",
    "#         with_tbptt=False,\n",
    "#     )\n",
    "\n",
    "    optims = next(n_choices(optim_grid(), 1))\n",
    "    print(net.hp.__class__(**optims))\n",
    "    is_tbptt = (1+int(net.hp.with_tbptt))\n",
    "    train(\n",
    "        soundbank,\n",
    "        net,\n",
    "        input_feature=feature,\n",
    "        target_feature=feature,\n",
    "        root_dir=\"./trainings/s2s-grid-lungs\",\n",
    "        \n",
    "#         batch_size=8,\n",
    "        batch_length=net.hop * is_tbptt,\n",
    "        tbptt_chunk_length=(net.hop*10*is_tbptt) if net.hp.with_tbptt else None,\n",
    "        shift_error=0,\n",
    "        downsampling=128 if not net.hp.with_tbptt else 1,\n",
    "        oversampling=32 if net.hp.with_tbptt else None,\n",
    "        \n",
    "        max_epochs=50,\n",
    "        limit_train_batches=None,\n",
    "        **optims,\n",
    "#         max_lr=4e-4,\n",
    "#         betas=(0.9, 0.92),\n",
    "        div_factor=5,\n",
    "        final_div_factor=1.,\n",
    "        pct_start=0.,\n",
    "        cycle_momentum=False,\n",
    "\n",
    "        CHECKPOINT_TRAINING=True,\n",
    "        MONITOR_TRAINING=True,\n",
    "        OUTPUT_TRAINING=\"mp3\",\n",
    "\n",
    "        every_n_epochs=10,\n",
    "        n_examples=4,\n",
    "        prompt_length=net.hop,\n",
    "        n_steps=int(12*(net.feature.sr//net.feature.hop_length) // net.hp.hop),\n",
    "        trainset=id_\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fbb01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "1e-32*1e-1200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e76f38",
   "metadata": {},
   "source": [
    "# Sample RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea233df4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for train_file in [*h5m.FileWalker(h5m.Sound.__re__, 'train-data/Heyr Himna.m4a')][0:]:\n",
    "#     h5m.sound_bank.callback(\"train.h5\", train_file, sr=16000,)\n",
    "\n",
    "#     soundbank = h5m.TypedFile(\"train.h5\", mode='r', keep_open=True)\n",
    "\n",
    "class GCPSoundBank(h5m.TypedFile):\n",
    "    snd = from_gcloud(h5m.Sound(sr=16000, mono=True, normalize=True))\n",
    "    \n",
    "    \n",
    "for id_, s in COUGH.items():\n",
    "    \n",
    "    GCPSoundBank.create(f\"train.h5\", s, parallelism=\"threads\", n_workers=8)\n",
    "    soundbank = GCPSoundBank(f\"train.h5\", mode='r', keep_open=True)\n",
    "    \n",
    "    feature = mmk.MuLawSignal(sr=soundbank.snd.attrs[\"sr\"],\n",
    "                                q_levels=256)\n",
    "    net = SampleRNN(\n",
    "        feature=feature,\n",
    "        chunk_length=16000*8,\n",
    "        frame_sizes = (16, 8, 8),\n",
    "        dim= 1024,\n",
    "        n_rnn = 1,\n",
    "        q_levels = 256,\n",
    "        embedding_dim = 256,\n",
    "        mlp_dim = 1024,\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        soundbank,\n",
    "        net,\n",
    "        input_feature=mmk.MultiScale(feature, net.frame_sizes, (*net.frame_sizes[:-1], 1)),\n",
    "        target_feature=feature,\n",
    "        root_dir=\"./trainings/srnn-cough\",\n",
    "        batch_size=32,\n",
    "        batch_length=512,\n",
    "        oversampling=1,\n",
    "        shift_error=0,\n",
    "        tbptt_len=(16000*8//512),\n",
    "        max_epochs=100,\n",
    "        limit_train_batches=8000,\n",
    "\n",
    "        max_lr=5e-4,\n",
    "        betas=(0.9, 0.99),\n",
    "        div_factor=5.,\n",
    "        final_div_factor=1.,\n",
    "        pct_start=0.,\n",
    "        cycle_momentum=False,\n",
    "\n",
    "        CHECKPOINT_TRAINING=True,\n",
    "        MONITOR_TRAINING=True,\n",
    "        OUTPUT_TRAINING=\"mp3\",\n",
    "\n",
    "        every_n_epochs=5,\n",
    "        n_examples=4,\n",
    "        prompt_length=16000,\n",
    "        n_steps=int(12*(net.feature.sr)),\n",
    "        temperature=torch.tensor([[1.51], [1.25], [1.05], [.95]]).repeat(1, int(12*(net.feature.sr))),\n",
    "        trainset=id_\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ce058",
   "metadata": {},
   "source": [
    "# Wavenets FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991fdad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "4**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11442594",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for train_file in h5m.FileWalker(h5m.Sound.__re__, 'train-data/sounds'):\n",
    "#     h5m.sound_bank.callback(\"train.h5\", train_file, sr=22050,)\n",
    "\n",
    "#     soundbank = h5m.TypedFile(\"train.h5\", mode='r', keep_open=True)\n",
    "class GCPSoundBank(h5m.TypedFile):\n",
    "    snd = from_gcloud(h5m.Sound(sr=16000, mono=True, normalize=True))\n",
    "    \n",
    "feature = mmk.Spectrogram(sr=16000,\n",
    "                            n_fft=1024,\n",
    "                            hop_length=128,\n",
    "                            coordinate='mag',\n",
    "                            center=False,\n",
    "                            normalize=True)\n",
    "net_grid = sampler_zipper(8,\n",
    "                        [dict(feature=feature,\n",
    "                             kernel_sizes=(4,),\n",
    "                              input_heads=2,\n",
    "                              output_heads=2,\n",
    "                            dims_dilated=(512,),\n",
    "                            dims_1x1=(),\n",
    "                            residuals_dim=None,\n",
    "                            apply_residuals=False,\n",
    "                            skips_dim=None,\n",
    "                            groups=2,\n",
    "                            act_f=nn.Tanh(),\n",
    "                            act_g=nn.Sigmoid(),\n",
    "                            pad_side=0,\n",
    "                            stride=1,\n",
    "                            bias=True,)],\n",
    "                         ParameterGrid([\n",
    "                             dict(\n",
    "                                 blocks=[(4,), (3,), (2,)],\n",
    "                                 scaled_activation=[True, False],\n",
    "#                                  phs=[\"b\", \"c\"],\n",
    "\n",
    "                             )\n",
    "                         ])\n",
    "                        )   \n",
    "    \n",
    "def optim_grid():\n",
    "    return instance_grid(\n",
    "        None,\n",
    "        dict(),\n",
    "        ParameterGrid([\n",
    "            dict(\n",
    "#                 batch_size=[8, 16, 32],\n",
    "#                 batch_length=[64, 64+32, 128, 128+32],\n",
    "#                 batch_length=[16, 32, 64],\n",
    "                max_lr=[7e-4, 5e-4, 3e-4],\n",
    "                betas=[(0.9, 0.9), (0.92, 0.92), (0.97, 0.95), (0.95, 0.97), (.92, .98)],\n",
    "            )\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "for id_, s in LUNGS.items():\n",
    "#     if id_ != \"Verdi_X_3_bis\":\n",
    "#         continue\n",
    "    for hp in net_grid:\n",
    "        GCPSoundBank.create(f\"train.h5\", s, parallelism=\"threads\", n_workers=8)\n",
    "        soundbank = GCPSoundBank(f\"train.h5\", mode='r', keep_open=True)\n",
    "\n",
    "    #     net = WaveNetFFT(\n",
    "    #         feature=feature,\n",
    "    #         input_heads=2,\n",
    "    #         output_heads=2,\n",
    "    #         scaled_activation=True,\n",
    "\n",
    "    #         kernel_sizes=(2,),\n",
    "    #         blocks=(4,),\n",
    "    #         dims_dilated=(1024,),\n",
    "    #         dims_1x1=(),\n",
    "    #         residuals_dim=None,\n",
    "    #         apply_residuals=False,\n",
    "    #         skips_dim=None,\n",
    "    #         groups=2,\n",
    "    #         act_f=nn.Tanh(),\n",
    "    #         act_g=nn.Sigmoid(),\n",
    "    #         pad_side=0,\n",
    "    #         stride=1,\n",
    "    #         bias=True,\n",
    "    #     )\n",
    "        net = WaveNetFFT(**hp)\n",
    "        \n",
    "        net.use_fast_generate = False\n",
    "\n",
    "        optims = next(n_choices(optim_grid(), 1))\n",
    "        print(net.hp)\n",
    "        print(net.hp.__class__(**optims))\n",
    "        train(\n",
    "            soundbank,\n",
    "            net,\n",
    "            root_dir=\"./trainings/wn-lungs\",\n",
    "            input_feature=feature,\n",
    "            target_feature=feature,\n",
    "            **optims,\n",
    "            batch_size=8,\n",
    "            batch_length=256,\n",
    "            downsampling=128,\n",
    "            shift_error=0,\n",
    "\n",
    "            max_epochs=50,\n",
    "            limit_train_batches=None,\n",
    "\n",
    "#             max_lr=5e-4,\n",
    "#             betas=(0.9, 0.92),\n",
    "            div_factor=5.,\n",
    "            final_div_factor=1.,\n",
    "            pct_start=0.,\n",
    "            cycle_momentum=False,\n",
    "\n",
    "            CHECKPOINT_TRAINING=True,\n",
    "            MONITOR_TRAINING=True,\n",
    "            OUTPUT_TRAINING=\"mp3\",\n",
    "\n",
    "            every_n_epochs=10,\n",
    "            n_examples=4,\n",
    "            prompt_length=64,\n",
    "            n_steps=int(12*(net.feature.sr//net.feature.hop_length)),\n",
    "    #         temperature=torch.tensor([[.85] * 200]),\n",
    "            trainset=id_\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCPSoundBank(h5m.TypedFile):\n",
    "    snd = from_gcloud(h5m.Sound(sr=16000, mono=True, normalize=True))\n",
    "\n",
    "GCPSoundBank.create(f\"train.h5\", ((*sets.values(),))[0], parallelism=\"threads\", n_workers=8)\n",
    "\n",
    "\n",
    "soundbank = GCPSoundBank(f\"train.h5\", mode='r', keep_open=True)\n",
    "\n",
    "\n",
    "net = SampleRNN(\n",
    "    feature=mmk.MuLawSignal(sr=soundbank.snd.attrs[\"sr\"],\n",
    "                            q_levels=256,\n",
    "                            normalize=True),\n",
    "    chunk_length=16000*8,\n",
    "    frame_sizes = (16, 8, 8),\n",
    "    dim= 512,\n",
    "    n_rnn = 2,\n",
    "    q_levels = 256,\n",
    "    embedding_dim = 256,\n",
    "    mlp_dim = 512,\n",
    ")\n",
    "dl = net.train_dataloader(soundbank, 8, 32, 1, 0)\n",
    "inp, trg = next(iter(dl))\n",
    "inp[0], trg[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
