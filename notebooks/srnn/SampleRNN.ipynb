{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimikit as mmk\n",
    "import h5mapper as h5m\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Sampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b115b",
   "metadata": {},
   "source": [
    "# Architecture + Feature => Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83de9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tp = h5m.TypedFile(\"test.h5\")\n",
    "net = mmk.SampleRNN()\n",
    "feat = mmk.MuLawSignal(sr=16000, normalize=True, q_levels=256)\n",
    "\n",
    "[st for st in net]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871f228",
   "metadata": {},
   "source": [
    "# Train Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5306ad7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getters = net.getters(batch_length=512, shift_error=0)\n",
    "batch = (\n",
    "    tuple(h5m.Input(proxy=tp.snd, getter=g_input, transform=feat.transform)\n",
    "          for g_input in getters['inputs']),\n",
    "    h5m.Target(proxy=tp.snd, getter=getters['targets'], transform=feat.transform),\n",
    ")\n",
    "dl = tp.serve(batch,\n",
    "              num_workers=8,\n",
    "              pin_memory=True,\n",
    "              persistent_workers=True, # need this!\n",
    "              batch_sampler=mmk.TBPTTSampler(tp.snd.shape[0],\n",
    "                                           batch_size=8,\n",
    "                                           chunk_length=16000*8,\n",
    "                                           seq_len=512))\n",
    "\n",
    "inp, outp = next(iter(dl))\n",
    "# inp.shape, outp.shape, inp, outp, tp.snd[1980:2000]\n",
    "outp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7e4bb",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e2854",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tr_loop = mmk.TrainLoop(\n",
    "    loader=dl,\n",
    "    net=net,\n",
    "    loss_fn=lambda out, trgt: {\"loss\": feat.loss_fn(out, trgt)},\n",
    "    optim=torch.optim.Adam(net.parameters(), lr=1e-3),\n",
    "    tbptt_len=2\n",
    ")\n",
    "\n",
    "Logs = h5m.typedfile(\"Logs\",\n",
    "                     {'ckpt': h5m.TensorDict(net.state_dict())}\n",
    "                    )\n",
    "logs = Logs(\"logs.h5\", mode='w')\n",
    "\n",
    "callbacks = [\n",
    "    mmk.MMKCheckpoint(h5_tensor_dict=logs.ckpt, epochs=1),\n",
    "]\n",
    "logger = mmk.LossLogger(logs)\n",
    "\n",
    "tr_loop.run(max_epochs=2,\n",
    "           logger=logger,\n",
    "           callbacks=callbacks,\n",
    "           limit_train_batches=10)\n",
    "\n",
    "logs.info()\n",
    "logs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3417627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs.index, logs.loss[:], net.load_state_dict(logs.ckpt['epoch=1-step=10']), logs.ckpt.load_hp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73821c6f",
   "metadata": {},
   "source": [
    "# Generate Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960685d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n_batches = 20\n",
    "batch_size = 8\n",
    "prompt_length = 32\n",
    "n_steps = 100\n",
    "\n",
    "# Gen DataLoader\n",
    "gen_getters = net.getters(batch_length=prompt_length, shift_error=0)\n",
    "gen_batch = (h5m.Input(proxy=tp.snd,\n",
    "                       getter=h5m.AsSlice(dim=0, shift=0, length=prompt_length),\n",
    "                       transform=feat.transform),)\n",
    "gen_dl = tp.serve(gen_batch,\n",
    "                  shuffle=False,\n",
    "                  batch_size=batch_size,\n",
    "                  sampler=torch.randint(0, tp.snd.shape[0], (batch_size*n_batches,),)\n",
    "                 )\n",
    "\n",
    "# Gen Loop\n",
    "outputs = {}\n",
    "loop = mmk.GenerateLoop(\n",
    "    network=net,\n",
    "    dataloader=gen_dl,\n",
    "    interfaces=[\n",
    "        mmk.DynamicDataInterface(\n",
    "            None,\n",
    "            getter=h5m.AsSlice(dim=1, shift=-net.shift, length=net.shift),\n",
    "            setter=mmk.Setter(dim=1)\n",
    "        ),\n",
    "#         temperature\n",
    "        mmk.DynamicDataInterface(\n",
    "            None,\n",
    "            prepare=lambda src: torch.rand(batch_size, n_steps) + 1,\n",
    "            getter=h5m.AsSlice(dim=1, shift=0, length=1),\n",
    "            setter=None,\n",
    "        )\n",
    "    ],\n",
    "    n_batches=n_batches,\n",
    "    n_steps=n_steps,\n",
    "    device='cpu',\n",
    "    process_outputs=lambda out, i: outputs.__setitem__(i, out)\n",
    ")\n",
    "\n",
    "loop.run()\n",
    "\n",
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c449b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}