{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimikit as mmk\n",
    "import h5mapper as h5m\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from models.wavenets import WaveNetFFT, WaveNetQx\n",
    "from models.srnns import SampleRNN\n",
    "from models.s2s import Seq2SeqLSTM, Seq2SeqLSTMv0\n",
    "from mains import train, generate\n",
    "\n",
    "from datasets import from_gcloud, INSECTS_X, VERDI_X, COUGH, LUNGS\n",
    "\n",
    "if os.path.exists(\"train-2.h5\"):\n",
    "    os.remove(\"train-2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37976b6",
   "metadata": {},
   "source": [
    "# SEQ2SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260607f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from grids import fft_grid, fft_io_grid\n",
    "\n",
    "\n",
    "class GCPSoundBank(h5m.TypedFile):\n",
    "    snd = from_gcloud(h5m.Sound(sr=22050, mono=True, normalize=True))\n",
    "    \n",
    "    \n",
    "for id_, s in COUGH.items():\n",
    "#     if id_ != \"Verdi_X_3_bis\":\n",
    "#         continue\n",
    "    \n",
    "    GCPSoundBank.create(f\"train-2.h5\", s, parallelism=\"threads\", n_workers=8)\n",
    "    soundbank = GCPSoundBank(f\"train-2.h5\", mode='r', keep_open=True)\n",
    "    \n",
    "    feature = mmk.Spectrogram(sr=soundbank.snd.attrs[\"sr\"],\n",
    "                                n_fft=2048, hop_length=512,\n",
    "                                coordinate='pol',\n",
    "                                center=False,\n",
    "                                normalize=True)\n",
    "\n",
    "    net = Seq2SeqLSTM(\n",
    "        feature=feature,\n",
    "        input_heads=1,\n",
    "        output_heads=1,\n",
    "        scaled_activation=True,\n",
    "        model_dim = 1024,\n",
    "        num_layers = 1,\n",
    "        n_lstm = 1,\n",
    "        bottleneck = \"add\",\n",
    "        n_fc = 1,\n",
    "        hop = 4,\n",
    "        weight_norm=False,\n",
    "        with_tbptt=False,\n",
    "        with_sampler=False,\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        soundbank,\n",
    "        net,\n",
    "        input_feature=feature,\n",
    "        target_feature=feature,\n",
    "        root_dir=\"./trainings/s2s-cough-pol\",\n",
    "        batch_size=8,\n",
    "        batch_length=4,\n",
    "        shift_error=0,\n",
    "        downsampling=32,\n",
    "\n",
    "        max_epochs=50,\n",
    "        limit_train_batches=None,\n",
    "\n",
    "        max_lr=4e-4,\n",
    "        betas=(0.9, 0.93),\n",
    "        div_factor=5.,\n",
    "        final_div_factor=1.,\n",
    "        pct_start=0.,\n",
    "        cycle_momentum=False,\n",
    "\n",
    "        CHECKPOINT_TRAINING=False,\n",
    "        MONITOR_TRAINING=True,\n",
    "        OUTPUT_TRAINING=\"\",\n",
    "\n",
    "        every_n_epochs=10,\n",
    "        n_examples=4,\n",
    "        prompt_length=4,\n",
    "        n_steps=int(12*(net.feature.sr//net.feature.hop_length) // net.hp.hop),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e76f38",
   "metadata": {},
   "source": [
    "# Sample RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "16000*4/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea233df4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for train_file in [*h5m.FileWalker(h5m.Sound.__re__, 'train-data/Heyr Himna.m4a')][0:]:\n",
    "#     h5m.sound_bank.callback(\"train.h5\", train_file, sr=16000,)\n",
    "\n",
    "#     soundbank = h5m.TypedFile(\"train.h5\", mode='r', keep_open=True)\n",
    "\n",
    "class GCPSoundBank(h5m.TypedFile):\n",
    "    snd = from_gcloud(h5m.Sound(sr=16000, mono=True, normalize=True))\n",
    "    \n",
    "    \n",
    "for id_, s in LUNGS.items():\n",
    "    for lr, betas in [(7e-4, (0.97, 0.995)), (5e-4, (.95, .985))]:\n",
    "\n",
    "        GCPSoundBank.create(f\"train-2.h5\", s, parallelism=\"threads\", n_workers=8)\n",
    "        soundbank = GCPSoundBank(f\"train-2.h5\", mode='r', keep_open=True)\n",
    "\n",
    "        feature = mmk.MuLawSignal(sr=soundbank.snd.attrs[\"sr\"],\n",
    "                                    q_levels=128)\n",
    "        net = SampleRNN(\n",
    "            feature=feature,\n",
    "            chunk_length=2048,\n",
    "            frame_sizes = (512, 64, 8, 8),\n",
    "            dim= 512,\n",
    "            n_rnn = 1,\n",
    "            q_levels = 128,\n",
    "            embedding_dim = 256,\n",
    "            mlp_dim = 512,\n",
    "        )\n",
    "        print(\"------------\", lr, betas)\n",
    "\n",
    "        train(\n",
    "            soundbank,\n",
    "            net,\n",
    "            input_feature=mmk.MultiScale(feature, net.frame_sizes, (*net.frame_sizes[:-1], 1)),\n",
    "            target_feature=feature,\n",
    "            root_dir=\"./trainings/srnn-lungs\",\n",
    "            batch_size=16,\n",
    "            batch_length=2048,\n",
    "            oversampling=32,\n",
    "            shift_error=0,\n",
    "            tbptt_chunk_length=2048*8,    #(16000*8//512),\n",
    "            max_epochs=1000,\n",
    "            limit_train_batches=None,\n",
    "\n",
    "#             max_lr=3e-4,\n",
    "            max_lr=lr,\n",
    "            betas=betas,\n",
    "#             betas=(0.95, 0.95),\n",
    "            div_factor=5.,\n",
    "            final_div_factor=1.,\n",
    "            pct_start=0.,\n",
    "            cycle_momentum=False,\n",
    "\n",
    "            CHECKPOINT_TRAINING=True,\n",
    "            MONITOR_TRAINING=True,\n",
    "            OUTPUT_TRAINING=\"mp3\",\n",
    "\n",
    "            every_n_epochs=50,\n",
    "            n_examples=6,\n",
    "            prompt_length=16000,\n",
    "            n_steps=int(12*(net.feature.sr)),\n",
    "            temperature=torch.tensor([[1.25], [1.1], [1.], [.995], [.95], [.75]]).repeat(1, int(12*(net.feature.sr))),\n",
    "            trainset=id_\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ce058",
   "metadata": {},
   "source": [
    "# Wavenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "4**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11442594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for train_file in h5m.FileWalker(h5m.Sound.__re__, 'train-data/sounds'):\n",
    "#     h5m.sound_bank.callback(\"train.h5\", train_file, sr=22050,)\n",
    "\n",
    "#     soundbank = h5m.TypedFile(\"train.h5\", mode='r', keep_open=True)\n",
    "class GCPSoundBank(h5m.TypedFile):\n",
    "    snd = from_gcloud(h5m.Sound(sr=16000, mono=True, normalize=True))\n",
    "    \n",
    "    \n",
    "for id_, s in LUNGS.items():\n",
    "#     if id_ != \"Verdi_X_3_bis\":\n",
    "#         continue\n",
    "    \n",
    "    GCPSoundBank.create(f\"train-2.h5\", s, parallelism=\"threads\", n_workers=8)\n",
    "    soundbank = GCPSoundBank(f\"train-2.h5\", mode='r', keep_open=True)\n",
    "    \n",
    "#     feature = mmk.Spectrogram(sr=soundbank.snd.attrs[\"sr\"],\n",
    "#                                 n_fft=2048,\n",
    "#                                 hop_length=512,\n",
    "#                                 coordinate='mag',\n",
    "#                                 center=False,\n",
    "#                                 normalize=True)\n",
    "    feature = mmk.MuLawSignal(sr=16000,\n",
    "                q_levels=256)\n",
    "    net = WaveNetQx(\n",
    "            feature=feature,\n",
    "            mlp_dim=512,\n",
    "\n",
    "            kernel_sizes=(4, ),\n",
    "            blocks=(4,),\n",
    "            dims_dilated=(1024,),\n",
    "            dims_1x1=(),\n",
    "            residuals_dim=None,\n",
    "            apply_residuals=False,\n",
    "            skips_dim=None,\n",
    "            groups=8,\n",
    "            pad_side=0,\n",
    "            stride=1,\n",
    "            bias=True,\n",
    "    )\n",
    "    net.use_fast_generate = True\n",
    "\n",
    "    train(\n",
    "        soundbank,\n",
    "        net,\n",
    "        root_dir=\"./trainings/wn-lungs-qx\",\n",
    "        input_feature=feature,\n",
    "        target_feature=feature,\n",
    "        batch_size=16,\n",
    "        batch_length=1024,\n",
    "        downsampling=4,\n",
    "        shift_error=0,\n",
    "\n",
    "        max_epochs=500,\n",
    "        limit_train_batches=8000,\n",
    "\n",
    "        max_lr=5e-4,\n",
    "        betas=(0.92, 0.975),\n",
    "        div_factor=5.,\n",
    "        final_div_factor=1.,\n",
    "        pct_start=0.,\n",
    "        cycle_momentum=False,\n",
    "\n",
    "        CHECKPOINT_TRAINING=True,\n",
    "        MONITOR_TRAINING=True,\n",
    "        OUTPUT_TRAINING=\"mp3\",\n",
    "\n",
    "        every_n_epochs=25,\n",
    "        n_examples=8,\n",
    "        prompt_length=256,\n",
    "#         n_steps=int(6*(net.feature.sr//net.feature.hop_length)),\n",
    "        n_steps=int(6*net.feature.sr),\n",
    "        temperature=torch.tensor([[2.1], [1.95], [1.75], [1.5], [1.], [.9], [.5], [.0005]]).repeat(1, int(6*(net.feature.sr))),\n",
    "        trainset=id_\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCPSoundBank(h5m.TypedFile):\n",
    "    snd = from_gcloud(h5m.Sound(sr=16000, mono=True, normalize=True))\n",
    "\n",
    "GCPSoundBank.create(f\"train.h5\", ((*sets.values(),))[0], parallelism=\"threads\", n_workers=8)\n",
    "\n",
    "\n",
    "soundbank = GCPSoundBank(f\"train.h5\", mode='r', keep_open=True)\n",
    "\n",
    "\n",
    "net = SampleRNN(\n",
    "    feature=mmk.MuLawSignal(sr=soundbank.snd.attrs[\"sr\"],\n",
    "                            q_levels=256,\n",
    "                            normalize=True),\n",
    "    chunk_length=16000*8,\n",
    "    frame_sizes = (16, 8, 8),\n",
    "    dim= 512,\n",
    "    n_rnn = 2,\n",
    "    q_levels = 256,\n",
    "    embedding_dim = 256,\n",
    "    mlp_dim = 512,\n",
    ")\n",
    "dl = net.train_dataloader(soundbank, 8, 32, 1, 0)\n",
    "inp, trg = next(iter(dl))\n",
    "inp[0], trg[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
